{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using your own data with `fluke`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will guide you through the steps required to use a custom dataset with `fluke`.\n",
    "\n",
    "Try this notebook: [![Open in Colab](https://img.shields.io/badge/Open_in_Colab-blue?style=flat-square&logo=google-colab&logoColor=yellow&labelColor=gray)\n",
    "](https://colab.research.google.com/github/makgyver/fluke/blob/main/tutorials/fluke_custom_dataset.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install `fluke` (if not already done)\n",
    "\n",
    "```bash\n",
    "pip install fluke-fl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your dataset function\n",
    "\n",
    "In order to make your dataset ready to be used in `fluke`, you need to define a function that returns\n",
    "a [DataContainer](../../fluke.data.datasets.md) object. A `DataContainer` is a simple class that\n",
    "wraps your data which is expected to be already split into training, and test sets.\n",
    "\n",
    "```{eval-rst}\n",
    "    .. hint::\n",
    "        You can have a dataset with no pre-defined test set. To make it work properly with ``fluke``, \n",
    "        you must set the training examples and labeles to two empty tensors. Then, in the configuration\n",
    "        you must set ``keep_test`` to ``False``.\n",
    "```\n",
    "\n",
    "The following is an example of a dataset function that returns a random dataset with 100 examples (80 for training and 20 for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.data.datasets import DataContainer\n",
    "import torch\n",
    "\n",
    "def MyDataset() -> DataContainer:\n",
    "\n",
    "    # Random dataset with 100 2D points from 2 classes\n",
    "    X = torch.randn(100, 2)\n",
    "    y = torch.randint(0, 2, (100,))\n",
    "\n",
    "    return DataContainer(X_train=X[:80],\n",
    "                         y_train=y[:80],\n",
    "                         X_test=X[80:],\n",
    "                         y_test=y[80:],\n",
    "                         num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your dataset with `fluke` CLI\n",
    "\n",
    "You can now use your dataset with `fluke` CLI. You need to specify in the configuration as the name\n",
    "of the dataset the fully qualified name of the function. Let's say you have saved the function above in a file\n",
    "called `my_dataset.py` and the function is called `my_dataset`, then you can use it as follows:\n",
    "\n",
    "```yaml\n",
    "dataset:\n",
    "  name: my_dataset.MyDataset\n",
    "  ...\n",
    "```\n",
    "\n",
    "Then, you can run `fluke` as usual:\n",
    "\n",
    "```bash\n",
    "fluke --config config.yaml federation fedavg.yaml\n",
    "```\n",
    "\n",
    "where `config.yaml` is the configuration file and `fedavg.yaml` is the configuration file for the federated averaging algorithm.\n",
    "\n",
    "```{eval-rst}\n",
    "    .. tip::\n",
    "       Make sure to configure the algorithm with a model that is compatible with the dataset!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your dataset with `fluke` API\n",
    "\n",
    "This use case is really straightforward! Instead of using `Datasets.get` use your own function to get the dataset!!\n",
    "\n",
    "Just for running the example, we define a tiny network that can work with our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.functional import F\n",
    "\n",
    "class MyMLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(2, 3)\n",
    "        self.fc2 = torch.nn.Linear(3, 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to run, for example, FedAVG on our dataset we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.data import DataSplitter\n",
    "from fluke import DDict\n",
    "from fluke.utils.log import Log\n",
    "from fluke.evaluation import ClassificationEval\n",
    "from fluke import FlukeENV\n",
    "\n",
    "dataset = MyDataset() # Here it is our dataset\n",
    "\n",
    "env = FlukeENV()\n",
    "env.set_seed(42) # we set a seed for reproducibility\n",
    "env.set_device(\"cpu\") # we use the CPU for this example\n",
    "# we set the evaluator to be used by both the server and the clients\n",
    "env.set_evaluator(ClassificationEval(eval_every=1, n_classes=dataset.num_classes))\n",
    "\n",
    "splitter = DataSplitter(dataset=dataset,\n",
    "                        distribution=\"iid\")\n",
    "\n",
    "client_hp = DDict(\n",
    "    batch_size=10,\n",
    "    local_epochs=5,\n",
    "    loss=\"CrossEntropyLoss\",\n",
    "    optimizer=DDict(\n",
    "      lr=0.01,\n",
    "      momentum=0.9,\n",
    "      weight_decay=0.0001),\n",
    "    scheduler=DDict(\n",
    "      gamma=1,\n",
    "      step_size=1)\n",
    ")\n",
    "\n",
    "hyperparams = DDict(client=client_hp,\n",
    "                    server=DDict(weighted=True),\n",
    "                    model=MyMLP()) # we use our network :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where the new federated algorithm comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluke.algorithms.fedavg import FedAVG\n",
    "algorithm = FedAVG(n_clients=2,\n",
    "                   data_splitter=splitter,\n",
    "                   hyper_params=hyperparams)\n",
    "\n",
    "logger = Log()\n",
    "algorithm.set_callbacks(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only just need to run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "algorithm.run(n_rounds=10, eligible_perc=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
